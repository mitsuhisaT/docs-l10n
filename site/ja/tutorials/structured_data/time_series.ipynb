{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Pmxv2ioyCRw"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "b-2ShX25yNWf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pa49bUnKyRgF"
   },
   "source": [
    "# 時系列予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11Ilg92myRcw"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/structured_data/time_series\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/structured_data/time_series.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrFrIDaEZAjE"
   },
   "source": [
    "Note: これらのドキュメントは私たちTensorFlowコミュニティが翻訳したものです。コミュニティによる 翻訳は**ベストエフォート**であるため、この翻訳が正確であることや[英語の公式ドキュメント](https://www.tensorflow.org/?hl=en)の 最新の状態を反映したものであることを保証することはできません。 この翻訳の品質を向上させるためのご意見をお持ちの方は、GitHubリポジトリ[tensorflow/docs](https://github.com/tensorflow/docs)にプルリクエストをお送りください。 コミュニティによる翻訳やレビューに参加していただける方は、 [docs-ja@tensorflow.org メーリングリスト](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ja)にご連絡ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GU8C5qm_4vZb"
   },
   "source": [
    "このチュートリアルは、回帰型ニューラルネットワーク(Recurrent Neural Networks) (RNNs)を利用した時系列予測の紹介です。二つのパートに分かれています：最初は、一つの時系列の変数の予測を行い、次に複数の時系列変数の予測を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rZnJaGTWQw0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TokBlnUhWFw9"
   },
   "source": [
    "## 気象データセット\n",
    "このチュートリアルでは、<a href=\"https://www.bgc-jena.mpg.de\" class=\"external\">マックスプランク生物地球科学研究所</a>が記録した<a href=\"https://www.bgc-jena.mpg.de/wetter/\" class=\"external\">[気象時系列データセット</a>を利用します。\n",
    "\n",
    "このデータセットは、気温、気圧、湿度などの14種の異なる特性を含んでいます。2003年から10分おきのデータセットが収集されています。効率を上げるために、2009年から2016年の間に収集されたデータのみを使用します。このセクションでは、François Cholletの著書[Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)で用意されたデータセットを使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyv_i85IWInT"
   },
   "outputs": [],
   "source": [
    "zip_path = tf.keras.utils.get_file(\n",
    "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "    fname='jena_climate_2009_2016.csv.zip',\n",
    "    extract=True)\n",
    "csv_path, _ = os.path.splitext(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TX6uGeeeWIkG"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VdbOWXiTWM2T"
   },
   "source": [
    "ざっとデータを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojHE-iCCWIhz"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfbpcV0MWQzl"
   },
   "source": [
    "上記のように、観測は10分ごとに記録されます。 これは、1時間の間に6つの観測があることを意味します。 同様に、1日には144（6x24）の観測が含まれます。\n",
    "\n",
    "特定の時間を想定して、6時間後の気温を予測するとします。この予測を行うには、5日間の観測を使用することを選択します。したがって、モデルをトレーニングするために、最後の720（5x144）観測を含むウィンドウを作成します。このような多くの構成が可能であり、このデータセットを実験するのに適しています。\n",
    "\n",
    "以下の関数は、モデルが学習するための上記の時間ウィンドウを返します。パラメータ `history_size`は、過去の情報ウィンドウのサイズです。`target_size`は予測する必要があるラベルです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7AoxQuTrWIbi"
   },
   "outputs": [],
   "source": [
    "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i)\n",
    "    # Reshape data from (history_size,) to (history_size, 1)\n",
    "    data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "    labels.append(dataset[i+target_size])\n",
    "  return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qoFJZmXBaxCc"
   },
   "source": [
    "次の両方のチュートリアルでは、データの最初の300,000行がトレーニングデータセットになり、残りは検証データセットになります。これは、約2100日分のトレーニングデータに相当します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ia-MPAHxbInX"
   },
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = 300000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EowWDtaNnH1y"
   },
   "source": [
    "再現性を確保するためのシードの設定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-x-GgENynHdx"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YEwr-NoWUpV"
   },
   "source": [
    "## パート1： 一変量時系列を予測する\n",
    "最初に、単一の特徴（温度）のみを使用してモデルをトレーニングし、それを使用して将来のその値の予測を行います。\n",
    "\n",
    "まず、データセットから温度のみを抽出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbdcnm1_WIY9"
   },
   "outputs": [],
   "source": [
    "uni_data = df['T (degC)']\n",
    "uni_data.index = df['Date Time']\n",
    "uni_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQB-46MyWZMm"
   },
   "source": [
    "このデータが経時的にどのように見えるかを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ftOExwAqWXSU"
   },
   "outputs": [],
   "source": [
    "uni_data.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejSEiDqBWXQa"
   },
   "outputs": [],
   "source": [
    "uni_data = uni_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-eFckdUUHWmT"
   },
   "source": [
    "ニューラルネットワークをトレーニングする前に、特徴をスケーリングすることが重要です。標準化は、平均を減算して各特徴の標準偏差で除算することにより、このスケーリングを行う一般的な方法です。値を[0,1]の範囲に再スケーリングする `tf.keras.utils.normalize`メソッドを使用することもできます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxbIic5TMlxx"
   },
   "source": [
    "Note: 平均と標準偏差は、トレーニングデータを使用してのみ計算する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eji6njXvHusN"
   },
   "outputs": [],
   "source": [
    "uni_train_mean = uni_data[:TRAIN_SPLIT].mean()\n",
    "uni_train_std = uni_data[:TRAIN_SPLIT].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Gob1YJYH0cH"
   },
   "source": [
    "データを標準化しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BO55yRD6H0Dx"
   },
   "outputs": [],
   "source": [
    "uni_data = (uni_data-uni_train_mean)/uni_train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gn8A_nrccKtn"
   },
   "source": [
    "単変量モデルのデータを作成しましょう。 パート1では、モデルには最後に記録された20個の温度観測が与えられ、次のタイムステップで温度を予測することを学習する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJJ-T49vWXOZ"
   },
   "outputs": [],
   "source": [
    "univariate_past_history = 20\n",
    "univariate_future_target = 0\n",
    "\n",
    "x_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT,\n",
    "                                           univariate_past_history,\n",
    "                                           univariate_future_target)\n",
    "x_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, None,\n",
    "                                       univariate_past_history,\n",
    "                                       univariate_future_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWpVMENsdp0N"
   },
   "source": [
    "これは、 `univariate_data`関数が返すものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feDd95XFdz5H"
   },
   "outputs": [],
   "source": [
    "print ('Single window of past history')\n",
    "print (x_train_uni[0])\n",
    "print ('\\n Target temperature to predict')\n",
    "print (y_train_uni[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hni3Jt9OMR1_"
   },
   "source": [
    "データが作成されたので、1つの例を見てみましょう。 ネットワークに提供される情報は青で表示され、赤い十字の値を予測する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qVukM9dRipop"
   },
   "outputs": [],
   "source": [
    "def create_time_steps(length):\n",
    "  return list(range(-length, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQeGvh7cWXMR"
   },
   "outputs": [],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "  labels = ['History', 'True Future', 'Model Prediction']\n",
    "  marker = ['.-', 'rx', 'go']\n",
    "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
    "  if delta:\n",
    "    future = delta\n",
    "  else:\n",
    "    future = 0\n",
    "\n",
    "  plt.title(title)\n",
    "  for i, x in enumerate(plot_data):\n",
    "    if i:\n",
    "      plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
    "               label=labels[i])\n",
    "    else:\n",
    "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "  plt.legend()\n",
    "  plt.xlim([time_steps[0], (future+5)*2])\n",
    "  plt.xlabel('Time-Step')\n",
    "  return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pd05iV-UWXKL"
   },
   "outputs": [],
   "source": [
    "show_plot([x_train_uni[0], y_train_uni[0]], 0, 'Sample Example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5rUJ_2YMWzG"
   },
   "source": [
    "### ベースライン\n",
    "モデルのトレーニングに進む前に、まず単純なベースラインを設定しましょう。 入力ポイントが与えられると、ベースラインメソッドはすべての履歴を調べ、次のポイントを最後の20観測の平均であると予測します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9nYWcxMMWnr"
   },
   "outputs": [],
   "source": [
    "def baseline(history):\n",
    "  return np.mean(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMcdFYKQMWlm"
   },
   "outputs": [],
   "source": [
    "show_plot([x_train_uni[0], y_train_uni[0], baseline(x_train_uni[0])], 0,\n",
    "           'Baseline Prediction Example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "067m6t8cMakb"
   },
   "source": [
    "リカレントニューラルネットワークを使用して、このベースラインを打つことができるかどうか見てみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H4crpOcoMlSe"
   },
   "source": [
    "### リカレントニューラルネットワーク\n",
    "再帰型ニューラルネットワーク（RNN）は、時系列データに適したタイプのニューラルネットワークです。 RNNは時系列を段階的に処理し、これまでに確認した情報を要約した内部状態を維持します。詳細は [RNN チュートリアル](https://www.tensorflow.org/tutorials/sequences/recurrent)を読んでください。このチュートリアルでは、Long Short Term Memory ([LSTM](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/LSTM)) と呼ばれる特殊なRNNレイヤーを使用します。\n",
    "\n",
    "ここで、 `tf.data`を使用してデータセットをシャッフル、バッチ処理、キャッシュします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kk-evkrmMWh9"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
    "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
    "val_univariate = val_univariate.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2AmKkyVS5Ht"
   },
   "source": [
    "次の視覚化は、バッチ処理後のデータの表現方法を理解するのに役立ちます。\n",
    "\n",
    "![時系列](images/time_series.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nagdTRNfPuZ"
   },
   "source": [
    "LSTMは、与えられているデータの入力形状を必要とすることがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDbpHosCMWZO"
   },
   "outputs": [],
   "source": [
    "simple_lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(8, input_shape=x_train_uni.shape[-2:]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "simple_lstm_model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOGZtDAqMtSi"
   },
   "source": [
    "サンプル予測を作成して、モデルの出力を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mPZbIKCMtLR"
   },
   "outputs": [],
   "source": [
    "for x, y in val_univariate.take(1):\n",
    "    print(simple_lstm_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYz6RN_mMyau"
   },
   "source": [
    "ここでモデルをトレーニングしましょう。 データセットのサイズが大きいため、時間を節約するために、通常行われる完全なトレーニングデータではなく、各エポックは200ステップだけ実行されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0opH9xi5MtIk"
   },
   "outputs": [],
   "source": [
    "EVALUATION_INTERVAL = 200\n",
    "EPOCHS = 10\n",
    "\n",
    "simple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n",
    "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                      validation_data=val_univariate, validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "euyPo_lyNryZ"
   },
   "source": [
    "#### 単純なLSTMモデルを使用して予測する\n",
    "簡単なLSTMをトレーニングしたので、いくつかの予測をしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2rRLrs8MtGU"
   },
   "outputs": [],
   "source": [
    "for x, y in val_univariate.take(3):\n",
    "  plot = show_plot([x[0].numpy(), y[0].numpy(),\n",
    "                    simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n",
    "  plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-AVEJyRNvt0"
   },
   "source": [
    "これはベースラインよりも良く見えます。 基本を理解したところで、パート2に進みましょう。ここでは、多変量時系列を操作します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VlJYi3_HXcw8"
   },
   "source": [
    "## Part 2: Forecast a multivariate time series\n",
    "\n",
    "## パート2： 多変量時系列を予測する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoxNZ2GM7DPm"
   },
   "source": [
    "The original dataset contains fourteen features. For simplicity, this section considers only three of the original fourteen. The features used are air temperature, atmospheric pressure, and air density. \n",
    "\n",
    "To use more features, add their names to this list.\n",
    "\n",
    "元のデータセットには14の特徴が含まれています。 簡単にするために、このセクションでは元の14のうち3つだけを考慮します。 使用される機能は、気温、大気圧、および空気密度です。\n",
    "\n",
    "さらに多くの機能を使用するには、その名前をこのリストに追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DphrB7bxSNDd"
   },
   "outputs": [],
   "source": [
    "features_considered = ['p (mbar)', 'T (degC)', 'rho (g/m**3)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IfQUSiJfUpXJ"
   },
   "outputs": [],
   "source": [
    "features = df[features_considered]\n",
    "features.index = df['Date Time']\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qSfhTZi5r15R"
   },
   "source": [
    "Let's have a look at how each of these features vary across time.\n",
    "\n",
    "これらの各機能が時間の経過とともにどのように変化するかを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdgC8zvGr21X"
   },
   "outputs": [],
   "source": [
    "features.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqStgZ-O1b3_"
   },
   "source": [
    "As mentioned, the first step will be to standardize the dataset using the mean and standard deviation of the training data.\n",
    "\n",
    "前述のように、最初のステップは、トレーニングデータの平均と標準偏差を使用してデータセットを標準化することです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7VuNIwfHRHx"
   },
   "outputs": [],
   "source": [
    "dataset = features.values\n",
    "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n",
    "data_std = dataset[:TRAIN_SPLIT].std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eJUeWDqploCt"
   },
   "outputs": [],
   "source": [
    "dataset = (dataset-data_mean)/data_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyuGuJUgjUK3"
   },
   "source": [
    "### Single step model\n",
    "In a single step setup, the model learns to predict a single point in the future based on some history provided.\n",
    "\n",
    "The below function performs the same windowing task as above, however, here it samples the past observation based on the step size given.\n",
    "\n",
    "### シングルステップモデル\n",
    "シングルステップセットアップでは、モデルは、提供された履歴に基づいて将来の単一のポイントを予測することを学習します。\n",
    "\n",
    "以下の関数は、上記と同じウィンドウ処理タスクを実行しますが、ここでは、指定されたステップサイズに基づいて過去の観測値をサンプリングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-rVX4d3OF86"
   },
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "  data = []\n",
    "  labels = []\n",
    "\n",
    "  start_index = start_index + history_size\n",
    "  if end_index is None:\n",
    "    end_index = len(dataset) - target_size\n",
    "\n",
    "  for i in range(start_index, end_index):\n",
    "    indices = range(i-history_size, i, step)\n",
    "    data.append(dataset[indices])\n",
    "\n",
    "    if single_step:\n",
    "      labels.append(target[i+target_size])\n",
    "    else:\n",
    "      labels.append(target[i:i+target_size])\n",
    "\n",
    "  return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWVGYwbN2ITI"
   },
   "source": [
    "In this tutorial, the network is shown data from the last five (5) days, i.e. 720 observations that are sampled every hour. The sampling is done every one hour since a drastic change is not expected within 60 minutes. Thus, 120 observation represent history of the last five days.  For the single step prediction model, the label for a datapoint is the temperature 12 hours into the future. In order to create a label for this, the temperature after 72(12*6) observations is used.\n",
    "\n",
    "このチュートリアルでは、ネットワークには過去5日間のデータが表示されます。つまり、1時間ごとにサンプリングされる720観測です。 60分以内に大幅な変化が予想されないため、サンプリングは1時間ごとに行われます。 したがって、120の観測は過去5日間の履歴を表します。 シングルステップ予測モデルの場合、データポイントのラベルは12時間後の気温です。 このためのラベルを作成するために、72（12 * 6）観測後の温度が使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HlhVGzPhmMYI"
   },
   "outputs": [],
   "source": [
    "past_history = 720\n",
    "future_target = 72\n",
    "STEP = 6\n",
    "\n",
    "x_train_single, y_train_single = multivariate_data(dataset, dataset[:, 1], 0,\n",
    "                                                   TRAIN_SPLIT, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=True)\n",
    "x_val_single, y_val_single = multivariate_data(dataset, dataset[:, 1],\n",
    "                                               TRAIN_SPLIT, None, past_history,\n",
    "                                               future_target, STEP,\n",
    "                                               single_step=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CamMObrwPhnp"
   },
   "source": [
    "Let's look at a single data-point.\n",
    "\n",
    "\n",
    "単一のデータポイントを見てみましょう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tVKm-ZIPls0"
   },
   "outputs": [],
   "source": [
    "print ('Single window of past history : {}'.format(x_train_single[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCWG4xgQ3O6E"
   },
   "outputs": [],
   "source": [
    "train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))\n",
    "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))\n",
    "val_data_single = val_data_single.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aWec9_nlxBl"
   },
   "outputs": [],
   "source": [
    "single_step_model = tf.keras.models.Sequential()\n",
    "single_step_model.add(tf.keras.layers.LSTM(32,\n",
    "                                           input_shape=x_train_single.shape[-2:]))\n",
    "single_step_model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYhUfWjwOPFN"
   },
   "source": [
    "Let's check out a sample prediction.\n",
    "\n",
    "サンプル予測をチェックしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yY7FodHVOPsH"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_single.take(1):\n",
    "  print(single_step_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0jnt2l2mwkl"
   },
   "outputs": [],
   "source": [
    "single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\n",
    "                                            steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                            validation_data=val_data_single,\n",
    "                                            validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ZAdeAnP5c72"
   },
   "outputs": [],
   "source": [
    "def plot_train_history(history, title):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(loss))\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8lBKA-z5yYV"
   },
   "outputs": [],
   "source": [
    "plot_train_history(single_step_history,\n",
    "                   'Single Step Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DfjrGAlEUp7i"
   },
   "source": [
    "#### Predict a single step future\n",
    "Now that the model is trained, let's make a few sample predictions. The model is given the history of three features over the past five days sampled every hour (120 data-points), since the goal is to predict the temperature, the plot only displays the past temperature. The prediction is made one day into the future (hence the gap between the history and prediction). \n",
    "\n",
    "#### シングルステップの先を予測する\n",
    "モデルがトレーニングされたので、サンプル予測をいくつか行ってみましょう。 モデルには、毎時サンプリングされた過去5日間の3つの特徴の履歴が与えられます（120データポイント）。目標は温度を予測することであるため、プロットは過去の温度のみを表示します。 予測は1日後に行われます（したがって、履歴と予測の間のギャップがあります）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1qmPLLVUpuN"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_single.take(3):\n",
    "  plot = show_plot([x[0][:, 1].numpy(), y[0].numpy(),\n",
    "                    single_step_model.predict(x)[0]], 12,\n",
    "                   'Single Step Prediction')\n",
    "  plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GnE087bJYSu"
   },
   "source": [
    "### Multi-Step model\n",
    "In a multi-step prediction model, given a past history, the model needs to learn to predict a range of future values. Thus, unlike a single step model, where only a single future point is predicted, a multi-step model predict a sequence of the future.\n",
    "\n",
    "For the multi-step model, the training data again consists of recordings over the past five days sampled every hour. However, here, the model needs to learn to predict the temperature for the next 12 hours. Since an obversation is taken every 10 minutes, the output is 72 predictions. For this task, the dataset needs to be prepared accordingly, thus the first step is just to create it again, but with a different target window.\n",
    "\n",
    "### マルチステップモデル\n",
    "マルチステップ予測モデルでは、過去の履歴を前提として、モデルは将来の値の範囲を予測することを学習する必要があります。 したがって、単一の未来点のみが予測されるシングルステップモデルとは異なり、マルチステップモデルは未来のシーケンスを予測します。\n",
    "\n",
    "マルチステップモデルの場合、トレーニングデータは、毎時間サンプリングされた過去5日間の記録で構成されます。 ただし、ここでは、モデルは次の12時間の温度を予測することを学習する必要があります。 観測(訳者注；obversationはobservationの誤り)は10分ごとに行われるため、出力は72予測です。 このタスクでは、それに応じてデータセットを準備する必要があります。したがって、最初のステップは、データセットを再度作成することですが、ターゲットウィンドウは異なります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZCk9fqyJZqX"
   },
   "outputs": [],
   "source": [
    "future_target = 72\n",
    "x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, 1], 0,\n",
    "                                                 TRAIN_SPLIT, past_history,\n",
    "                                                 future_target, STEP)\n",
    "x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, 1],\n",
    "                                             TRAIN_SPLIT, None, past_history,\n",
    "                                             future_target, STEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LImXPwAGRtWy"
   },
   "source": [
    "Let's check out a sample data-point.\n",
    "\n",
    "サンプルのデータポイントを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SpWDcBkQRwS-"
   },
   "outputs": [],
   "source": [
    "print ('Single window of past history : {}'.format(x_train_multi[0].shape))\n",
    "print ('\\n Target temperature to predict : {}'.format(y_train_multi[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjR4PJArMOpA"
   },
   "outputs": [],
   "source": [
    "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
    "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
    "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZcg8FWpSG8K"
   },
   "source": [
    "Plotting a sample data-point.\n",
    "\n",
    "サンプルデータポイントのプロット。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksXKVbwBV7D3"
   },
   "outputs": [],
   "source": [
    "def multi_step_plot(history, true_future, prediction):\n",
    "  plt.figure(figsize=(12, 6))\n",
    "  num_in = create_time_steps(len(history))\n",
    "  num_out = len(true_future)\n",
    "\n",
    "  plt.plot(num_in, np.array(history[:, 1]), label='History')\n",
    "  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
    "           label='True Future')\n",
    "  if prediction.any():\n",
    "    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
    "             label='Predicted Future')\n",
    "  plt.legend(loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCQKetflZRMF"
   },
   "source": [
    "In this plot and subsequent similar plots, the history and the future data are sampled every hour.\n",
    "\n",
    "このプロットとその後の同様のプロットでは、履歴と将来のデータが1時間ごとにサンプリングされます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6G8bacQR4w2"
   },
   "outputs": [],
   "source": [
    "for x, y in train_data_multi.take(1):\n",
    "  multi_step_plot(x[0], y[0], np.array([0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XOjz8DzZ4HFS"
   },
   "source": [
    "Since the task here is a bit more complicated than the previous task, the model now consists of two LSTM layers. Finally, since 72 predictions are made, the dense layer outputs 72 predictions.\n",
    "\n",
    "ここでのタスクは前のタスクよりも少し複雑であるため、モデルは2つのLSTMレイヤーで構成されています。 最後に、72個の予測が行われるため、denseレイヤーは72個の予測を出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "byAl0NKSNBP6"
   },
   "outputs": [],
   "source": [
    "multi_step_model = tf.keras.models.Sequential()\n",
    "multi_step_model.add(tf.keras.layers.LSTM(32,\n",
    "                                          return_sequences=True,\n",
    "                                          input_shape=x_train_multi.shape[-2:]))\n",
    "multi_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))\n",
    "multi_step_model.add(tf.keras.layers.Dense(72))\n",
    "\n",
    "multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvB7zBqVSMyl"
   },
   "source": [
    "Let's see how the model predicts before it trains.\n",
    "\n",
    "トレーニングする前にモデルがどのように予測するかを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13_ZWvB9SRlZ"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(1):\n",
    "  print (multi_step_model.predict(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uwOhXo3Oems"
   },
   "outputs": [],
   "source": [
    "multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
    "                                          steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                          validation_data=val_data_multi,\n",
    "                                          validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKfQoBjQ5l7U"
   },
   "outputs": [],
   "source": [
    "plot_train_history(multi_step_history, 'Multi-Step Training and validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oDg94-yq4pas"
   },
   "source": [
    "#### Predict a multi-step future\n",
    "Let's now have a look at how well your network has learnt to predict the future.\n",
    "\n",
    "#### マルチステップの未来を予測する\n",
    "次に、ネットワークが将来を予測するためにどれだけよく学んだかを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dt22wq6fyIBU"
   },
   "outputs": [],
   "source": [
    "for x, y in val_data_multi.take(3):\n",
    "  multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOzaIRYBhqwg"
   },
   "source": [
    "## Next steps\n",
    "This tutorial was a quick introduction to time series forecasting using an RNN. You may now try to predict the stock market and become a billionaire.\n",
    "\n",
    "In addition, you may also write a generator to yield data (instead of the uni/multivariate_data function), which would be more memory efficient. You may also check out this [time series windowing](https://www.tensorflow.org/guide/data#time_series_windowing) guide and use it in this tutorial.\n",
    "\n",
    "For further understanding, you may read Chapter 15 of [Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/), 2nd Edition and Chapter 6 of [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python).\n",
    "\n",
    "## 次のステップ\n",
    "このチュートリアルは、RNNを使用した時系列予測の簡単な紹介です。 あなたは今、株式市場を予測して億万長者になることを試みるかもしれません。\n",
    "\n",
    "さらに、(uni/multivariate_data関数の代わりに)データを生成するジェネレーターを作成することもできます。これにより、メモリ効率が向上します。この[時系列のウィンドウ処理](https://www.tensorflow.org/guide/data#time_series_windowing)ガイドを確認して、このチュートリアルで使用することもできます。\n",
    "\n",
    "詳細については、第15章[Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)、と[Pythonによる深層学習](https://www.manning.com/books/deep-learning-with-python)第2版の第6章を参照してください。"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "dj3rpi377dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
